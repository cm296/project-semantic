{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import sys\n",
    "sys.path.append('/Users/cmagri1/OneDrive - Johns Hopkins/git')\n",
    "from torch import nn\n",
    "import torch\n",
    "from torchvision.models.alexnet import alexnet\n",
    "from tqdm import tqdm\n",
    "\n",
    "from EncodingModel_cm296 import utils as emutils\n",
    "from EncodingModel_cm296 import feature_extractor as emfe\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "from utilsCM import Subject\n",
    "from utilsCM import cv_regression #Predicting fMRI reponses with features (Alexnet activations) \n",
    "#cv_regression computes cross-validated ridge regression. cross-validation groupings were pre-set based\n",
    "#on fMRI design. 9-categories out, 9 folds. r is averaged over folds, weights are computed over all data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load word2sense\n",
    "#already preprocessed in MATLAB so that Wrd2Sns and THINGs overlap --> we have IMAGES, LABELS and SENSES\n",
    "pathtofile = '../code-00-preprocessdataset/'\n",
    "Wrd2Sense = pd.read_csv(pathtofile + \"ThingsWrd2Sns.txt\", sep=\",\")\n",
    "ImgInfo = pd.read_csv(pathtofile + \"KeptTHINGSInfo.txt\", sep=\",\")\n",
    "WordInfThings= ImgInfo.Word.to_numpy() ##to find the words that are images in THINGS dataset\n",
    "pathtoTHINGS = '/Users/cmagri1/OneDrive - Johns Hopkins/Project-Word2Sense/THINGSdataset/Main/images'\n",
    "PathToImgs = 'data-object2vec/stimuli'\n",
    "savepath = '../../../data-00/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute DNN features\n",
    "def object_by_feature(PathToImgs,keyword,ilayer,resolutionval, savepath,WordInf=[],pretrained=True):\n",
    "    if pretrainedModel:\n",
    "        namefile = savepath+ keyword + '_' + ilayer \n",
    "    else:\n",
    "        namefile = savepath+ keyword + '_' + ilayer +\"_untrained\"\n",
    "        \n",
    "    if os.path.isfile(namefile+\".csv\"): #if it's already saves\n",
    "        \n",
    "        print('loading file with '+ keyword+ ' stimuli features for ' + ilayer)\n",
    "        features = pd.read_csv(namefile+\".csv\"  , sep=\",\", header=None, index_col=0)\n",
    "        condition_features = {}\n",
    "        for index, row in features.iterrows():\n",
    "            condition_features[index] = row \n",
    "            \n",
    "            \n",
    "    else:\n",
    "        \n",
    "        if keyword == 'things':\n",
    "            WordInf = WordInfThings\n",
    "        \n",
    "        \n",
    "        print('Computing '+ keyword+ ' stimuli features for ' + ilayer)\n",
    "        #Specify the model\n",
    "        model = emfe.AlexNet(ilayer,pretrained_val=pretrained);      \n",
    "        condition_features = emutils.compute_features(model, PathToImgs,resolutionval,WordInf)\n",
    "#         features = \n",
    "        pd.DataFrame(condition_features).transpose().to_csv(namefile+\".csv\", index = True, header=False)\n",
    "#         features.to_csv(namefile+\".csv\", index = True, header=False)\n",
    "        np.save(namefile,condition_features)\n",
    "#     layer_by_features[ilayer] = features; #create multistructure with all layers\n",
    "    return condition_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "pretrainedModel = True\n",
    "resolutionval = 227;\n",
    "\n",
    "\n",
    "layer = {'conv_1', 'conv_5', 'fc_3'};\n",
    "ROI = {'LOC'}\n",
    "Sub = [1,2,3,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing object2vec stimuli features for conv_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [00:13<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing things stimuli features for conv_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1470/1470 [11:33<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ROI PFS prediction for conv_1\n",
      "Computing ROI PPA prediction for conv_1\n",
      "Computing ROI EVC prediction for conv_1\n",
      "Computing ROI PFS prediction for conv_1\n",
      "Computing ROI PPA prediction for conv_1\n",
      "Computing ROI EVC prediction for conv_1\n",
      "Computing ROI PFS prediction for conv_1\n",
      "Computing ROI PPA prediction for conv_1\n",
      "Computing ROI EVC prediction for conv_1\n",
      "Computing ROI PFS prediction for conv_1\n",
      "Computing ROI PPA prediction for conv_1\n",
      "Computing ROI EVC prediction for conv_1\n",
      "Computing object2vec stimuli features for fc_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [00:25<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing things stimuli features for fc_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1470/1470 [16:01<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ROI PFS prediction for fc_3\n",
      "Computing ROI PPA prediction for fc_3\n",
      "Computing ROI EVC prediction for fc_3\n",
      "Computing ROI PFS prediction for fc_3\n",
      "Computing ROI PPA prediction for fc_3\n",
      "Computing ROI EVC prediction for fc_3\n",
      "Computing ROI PFS prediction for fc_3\n",
      "Computing ROI PPA prediction for fc_3\n",
      "Computing ROI EVC prediction for fc_3\n",
      "Computing ROI PFS prediction for fc_3\n",
      "Computing ROI PPA prediction for fc_3\n",
      "Computing ROI EVC prediction for fc_3\n",
      "Computing object2vec stimuli features for conv_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [00:24<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing things stimuli features for conv_5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1470/1470 [16:34<00:00,  1.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing ROI PFS prediction for conv_5\n",
      "Computing ROI PPA prediction for conv_5\n",
      "Computing ROI EVC prediction for conv_5\n",
      "Computing ROI PFS prediction for conv_5\n",
      "Computing ROI PPA prediction for conv_5\n",
      "Computing ROI EVC prediction for conv_5\n",
      "Computing ROI PFS prediction for conv_5\n",
      "Computing ROI PPA prediction for conv_5\n",
      "Computing ROI EVC prediction for conv_5\n",
      "Computing ROI PFS prediction for conv_5\n",
      "Computing ROI PPA prediction for conv_5\n",
      "Computing ROI EVC prediction for conv_5\n",
      "things dataset activations in DNN conv_5 size: (1470, 9216)\n",
      "weights size: (200, 9216)\n",
      "ROI pred size: (1470, 200)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for ilayer in layer:    \n",
    "\n",
    "     #Compute features of CNN\n",
    "     #---------Object2Vect-----------------\n",
    "    keyword = 'object2vec'\n",
    "    object2vec_features = object_by_feature(PathToImgs,keyword,ilayer,resolutionval,savepath,pretrained=pretrainedModel)\n",
    "    \n",
    "#     #---------THINGS-----------------\n",
    "    keyword = 'things'\n",
    "    things_features = object_by_feature(pathtoTHINGS,keyword,ilayer,resolutionval,savepath,pretrained=pretrainedModel)\n",
    "    things_features_df = pd.DataFrame(things_features).transpose()\n",
    "    \n",
    "    for iSub in Sub:\n",
    "        for iROI in ROI:\n",
    "            subject = Subject(iSub,[iROI])\n",
    "            #predict fMRI using object2vec DNN activations\n",
    "            weights, r = cv_regression(object2vec_features, subject, l2=0)\n",
    "            \n",
    "            #     #---Compute Predicted ROI response to THINGS dataset\n",
    "            print(\"Computing ROI \" + iROI + \" prediction for \" + ilayer)    \n",
    "            ROIpred = {}\n",
    "            ROIpred = np.matmul(things_features_df.iloc[:,:].to_numpy(),weights.transpose())\n",
    "            \n",
    "            if pretrainedModel:\n",
    "                np.save(savepath + '/ROIpred_Sub' + str(iSub) + '_' + iROI + \"_\" + ilayer, ROIpred)\n",
    "            else:\n",
    "                np.save(savepath + '/ROIpred_Sub' + str(iSub) + '_' + iROI + \"_\" + ilayer + '_untrained', ROIpred)\n",
    "print('things dataset activations in DNN '+ ilayer +' size: ' + str(things_features_df.shape))\n",
    "print('weights size: ' + str(weights.shape))\n",
    "print('ROI pred size: ' + str(ROIpred.shape))\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
