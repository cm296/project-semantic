{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from curvaturemodel import curvature as curv \n",
    "from curvaturemodel import edge as edg \n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/Users/cmagri1/OneDrive - Johns Hopkins/git')\n",
    "from EncodingModel_cm296 import utils as emutils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = '../../../data-00/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.transforms import functional as transforms\n",
    "\n",
    "\n",
    "def listdir(dir, path=True):\n",
    "    files = os.listdir(dir)\n",
    "    files = [f for f in files if f != '.DS_Store']\n",
    "    files = sorted(files)\n",
    "    if path:\n",
    "        files = [os.path.join(dir, f) for f in files]\n",
    "    return files\n",
    "\n",
    "imagenet_mean = (0.485, 0.456, 0.406)\n",
    "imagenet_std = (0.229, 0.224, 0.225)\n",
    "\n",
    "\n",
    "def image_to_model(image,model):\n",
    "    if isinstance(image, str):\n",
    "        image = Image.open(image)\n",
    "#         .convert('LAD')\n",
    "        image = transforms.to_grayscale(image)\n",
    "        image = transforms.resize(image, (96, 96))    # Or whatever resolution you want\n",
    "        image = transforms.to_tensor(image)\n",
    "        image = transforms.normalize(image, mean=(0.5,), std=(0.5,))\n",
    "        with torch.no_grad():\n",
    "            features = model(image.unsqueeze(dim=0)).squeeze(dim=0)\n",
    "        features = torch.flatten(features)\n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "def compute_features_curvature(model, conditionsPath,WordInf =[]):\n",
    "    #takes model and loads the features for that image, needs path to of files in directory\n",
    "\n",
    "    conditions = listdir(conditionsPath)\n",
    "\n",
    "    #If it's THINGS this ensures we only pick up images from List of 1470\n",
    "    if len(WordInf) > 0:\n",
    "        new_conditions = []\n",
    "        for c in conditions:\n",
    "            w = c.split('/')[-1]\n",
    "            if w in WordInf:\n",
    "                new_conditions.append(c)\n",
    "        conditions = new_conditions\n",
    "\n",
    "    condition_features = {}\n",
    "    for c in tqdm(conditions):\n",
    "        c_name = c.split('/')[-1]\n",
    "        \n",
    "        stimuli = listdir(c)\n",
    "        \n",
    "        #resize according to resolution and square the image\n",
    "        features = [image_to_model(s,model) for s in stimuli]\n",
    "#         features = torch.flatten(features)\n",
    "        features = torch.stack(features)\n",
    "        feats = features.mean(dim=0).cpu().numpy()\n",
    "        condition_features[c_name] = feats\n",
    "    return condition_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Compute DNN features\n",
    "def object_by_feature(namemodel,keyword, savepath,WordList=[]):\n",
    "\n",
    "    namefile = savepath+ keyword + '_' + namemodel \n",
    "        \n",
    "    if os.path.isfile(namefile): #if it's already saves\n",
    "        \n",
    "        print('loading file with '+ keyword+ ' stimuli features for ' + namemodel + ' model')\n",
    "        features = pd.read_csv(namefile+\".csv\"  , sep=\",\", header=None, index_col=0)\n",
    "        condition_features = {}\n",
    "        for index, row in features.iterrows():\n",
    "            condition_features[index] = row \n",
    "            \n",
    "            \n",
    "    else:\n",
    "        \n",
    "        if keyword is 'things':\n",
    "            PathToImgs = '../../../../THINGSdataset/Main/images'\n",
    "            WordList = pd.read_csv('../code-00-preprocessdataset/' + \"KeptTHINGSInfo.txt\", sep=\",\")['Word'].to_numpy()\n",
    "        elif keyword is 'object2vec':\n",
    "            PathToImgs = 'data-object2vec/stimuli'\n",
    "        \n",
    "    \n",
    "        \n",
    "        print('Computing '+ keyword+ ' stimuli features for ' + namemodel + ' model')\n",
    "        #Specify the model\n",
    "        if namemodel is 'Curvature':\n",
    "            model = curv.CurvatureModel()\n",
    "        elif namemodel is 'Edge':\n",
    "            model = edg.EdgeModel()\n",
    "            \n",
    "        condition_features = compute_features_curvature(model, PathToImgs,WordInf = WordList)\n",
    "#         print(condition_features)\n",
    "\n",
    "        \n",
    "#         pd.DataFrame(condition_features).transpose().to_csv(namefile+\".csv\", index = True, header=False)\n",
    "        np.save(namefile,condition_features)\n",
    "    return condition_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/81 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing object2vec stimuli features for Curvature model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/81 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "flatten(): argument 'input' (position 1) must be Tensor, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-36f7ef23f1e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Curvature'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'object2vec'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mobject2vec_curv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_by_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeyword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msavepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-fe154064ac9e>\u001b[0m in \u001b[0;36mobject_by_feature\u001b[0;34m(namemodel, keyword, savepath, WordList)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEdgeModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mcondition_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_features_curvature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPathToImgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mWordInf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;31m#         print(condition_features)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-8ae482654209>\u001b[0m in \u001b[0;36mcompute_features_curvature\u001b[0;34m(model, conditionsPath, WordInf)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m#resize according to resolution and square the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mimage_to_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstimuli\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: flatten(): argument 'input' (position 1) must be Tensor, not list"
     ]
    }
   ],
   "source": [
    "#Compute features of CNN\n",
    "#---------Object2Vect-----------------\n",
    "model = 'Curvature'\n",
    "keyword = 'object2vec'\n",
    "object2vec_curv = object_by_feature(model,keyword,savepath)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "namefile = savepath+ keyword + '_' + model \n",
    "thisfile = np.load(namefile + '.npy',allow_pickle=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "thisfilearray = list(thisfile.item().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 96, 96)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thisfilearray[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(thisfilearray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "thisfilevalues_list = list(thisfilevalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(320, 96, 96)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thisfileitems[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute features of CNN\n",
    "#---------Object2Vect-----------------\n",
    "model = 'Edge'\n",
    "keyword = 'things'\n",
    "object2vec_edge = object_by_feature(model,keyword,savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute fMRI predictions\n",
    "layer = {'conv_1'};\n",
    "ROI = {'PPA'}\n",
    "Sub = [1]\n",
    "\n",
    "\n",
    "for iSub in Sub:\n",
    "        for iROI in ROI:\n",
    "            subject = Subject(iSub,[iROI])\n",
    "            #predict fMRI using object2vec DNN activations\n",
    "            weights, r = cv_regression(object2vec_features, subject, l2=0)\n",
    "            \n",
    "            #     #---Compute Predicted ROI response to THINGS dataset\n",
    "            print(\"Computing ROI \" + iROI + \" prediction for \" + ilayer)    \n",
    "            ROIpred = {}\n",
    "            ROIpred = np.matmul(things_features_df.iloc[:,:].to_numpy(),weights.transpose())\n",
    "            \n",
    "            if pretrainedModel:\n",
    "                np.save(savepath + '/ROIpred_Sub' + str(iSub) + '_' + iROI + \"_\" + ilayer, ROIpred)\n",
    "            else:\n",
    "                np.save(savepath + '/ROIpred_Sub' + str(iSub) + '_' + iROI + \"_\" + ilayer + '_untrained', ROIpred)\n",
    "print('things dataset activations in DNN '+ ilayer +' size: ' + str(things_features_df.shape))\n",
    "print('weights size: ' + str(weights.shape))\n",
    "print('ROI pred size: ' + str(ROIpred.shape))\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
