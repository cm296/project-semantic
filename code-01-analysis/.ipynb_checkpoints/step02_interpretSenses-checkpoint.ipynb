{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import utilsCM\n",
    "import csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load word2sense\n",
    "#already preprocessed in MATLAB so that Wrd2Sns and THINGs overlap --> we have IMAGES, LABELS and SENSES\n",
    "pathtofile = '../code-00-preprocessdataset/'\n",
    "W2S = pd.read_csv(pathtofile + \"ThingsWrd2Sns.txt\", sep=\",\")\n",
    "Y_embeddings = W2S.values[:,1:W2S.shape[1]-1].astype(np.float)\n",
    "\n",
    "tresh_bonf = utilsCM.p2r(.05/Y_embeddings.shape[1], 1470)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keyword = {'ROIpred'}\n",
    "keyword = {'DNNActvtn','ROIpred'}\n",
    "\n",
    "layer =  {'conv_1','conv_5','fc_3'}\n",
    "\n",
    "ROI = {'EVC', 'ObjectROI'}\n",
    "\n",
    "# Sub = [1,2,3,4]\n",
    "Sub = [1,2,3,4]\n",
    "\n",
    "#how many components to keep?\n",
    "Keepncomps = [20]\n",
    "pretrained_val = False\n",
    "\n",
    "datapath = '../../../data-01/'\n",
    "savepath = '../../../data-02/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "W2S = pd.read_csv(pathtofile + \"ThingsWrd2Sns.txt\", sep=\",\").set_index('item').drop(labels='sense2251', axis=1)\n",
    "\n",
    "##Showing histograms for senses above threshold\n",
    "myDict = {}\n",
    "\n",
    "for ilayer in layer:\n",
    "    \n",
    "    for ikeyword in keyword:        \n",
    "        \n",
    "        for icomps in Keepncomps:\n",
    "            thisPrediction = []\n",
    "            \n",
    "            if ikeyword is 'DNNActvtn':\n",
    "                if not pretrained_val:\n",
    "                    filename = 'PredictSENSES_' + ikeyword + '_'+ ilayer + '_'+ str(icomps) +'PCs_untrained'\n",
    "                    csvfilename = savepath + ikeyword+ \"_\" + ilayer + '_'+ str(icomps) +'PCs_untrained.csv'\n",
    "                else:\n",
    "                    filename = 'PredictSENSES_' + ikeyword + '_'+ ilayer + '_'+ str(icomps) +'PCs'\n",
    "                    csvfilename = savepath + ikeyword+ \"_\" + ilayer + '_'+ str(icomps) +'PCs.csv'\n",
    "                    \n",
    "                thisPrediction = np.load(datapath + filename + '.npy')\n",
    "                \n",
    "                sortedIndeces = np.argsort(thisPrediction)[::-1][0:9] #first 10 senses indeces, from highest to least hgih\n",
    "                \n",
    "                \n",
    "                Subset_W2S = W2S.iloc[:,sortedIndeces]\n",
    "                WeightedWords_rows = (Subset_W2S != 0).any(axis=1)#finds rows of zeros for those tops senses\n",
    "                new_W2S = W2S.loc[WeightedWords_rows] #takes them off from dataset\n",
    "                \n",
    "                ##Goes through each sense, prints out the top ten words and save them in a csv\n",
    "                listOfWeights = []\n",
    "                count = 0  \n",
    "                for i in sortedIndeces:\n",
    "                    count += 1\n",
    "                    listOfWeights.append(\"Top \"+ str(count) + \" Sense \" + str(i))\n",
    "                    listOfWeights.append(new_W2S.iloc[:,i].sort_values(0)[::-1][0:9])\n",
    "                    \n",
    "                    \n",
    "                \n",
    "                #save in csv file\n",
    "                with open(csvfilename, 'w', newline='') as csvfile:\n",
    "                    wr = csv.writer(csvfile, quoting=csv.QUOTE_ALL)\n",
    "                    wr.writerow(listOfWeights)\n",
    "            \n",
    "            \n",
    "            elif ikeyword is 'ROIpred':\n",
    "                \n",
    "                for iROI in ROI:\n",
    "                    thisPrediction = []\n",
    "                    if not pretrained_val:\n",
    "                        filename = 'PredictSENSES_' + ikeyword + '_' +iROI + '_'+ ilayer + '_'+ str(icomps) +'PCs_untrained'\n",
    "                        csvfilename = savepath + ikeyword + \"_\" + iROI +'_' + ilayer + '_'+ str(icomps) +'PCs_untrained.csv'\n",
    "                    else:\n",
    "                        filename = 'PredictSENSES_' + ikeyword + '_' +iROI + '_'+ ilayer + '_'+ str(icomps) +'PCs'\n",
    "                        csvfilename = savepath + ikeyword + \"_\" + iROI +'_' + ilayer + '_'+ str(icomps) +'PCs.csv'\n",
    "\n",
    "                    \n",
    "                    thisPrediction = np.load(datapath + filename + '.npy')\n",
    "                    \n",
    "                    sortedIndeces = np.argsort(thisPrediction)[::-1][0:9] #first 10 senses indeces, from highest to least hgih\n",
    "                    Subset_W2S = W2S.iloc[:,sortedIndeces]#eliminate rows of zeros\n",
    "                    WeightedWords_rows = (Subset_W2S != 0).any(axis=1)\n",
    "                    new_W2S = W2S.loc[WeightedWords_rows] #takes them off from dataset\n",
    "\n",
    "                    listOfWeights = []\n",
    "                    count = 0\n",
    "                    for i in sortedIndeces:\n",
    "                        count += 1\n",
    "                        listOfWeights.append(\"Top \"+ str(count) + \" Sense \" + str(i))\n",
    "                        listOfWeights.append(new_W2S.iloc[:,i].sort_values(0)[::-1][0:9])\n",
    "                                    \n",
    "                    with open(csvfilename, 'w', newline='') as csvfile:\n",
    "                        wr = csv.writer(csvfile, quoting=csv.QUOTE_ALL)\n",
    "                        wr.writerow(listOfWeights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Top 1 Sense 213', item\n",
       " puck        0.028042\n",
       " zucchini    0.000000\n",
       " fox         0.000000\n",
       " gazelle     0.000000\n",
       " garter      0.000000\n",
       " garlic      0.000000\n",
       " funnel      0.000000\n",
       " fungus      0.000000\n",
       " fudge       0.000000\n",
       " Name: sense214, dtype: float64, 'Top 2 Sense 856', item\n",
       " chive         0.488692\n",
       " tortellini    0.479950\n",
       " pesto         0.458424\n",
       " ravioli       0.457889\n",
       " coleslaw      0.449769\n",
       " steak         0.416888\n",
       " crouton       0.332972\n",
       " guacamole     0.327699\n",
       " sauce         0.294452\n",
       " Name: sense857, dtype: float64, 'Top 3 Sense 144', item\n",
       " blouse        0.347015\n",
       " shirt         0.275378\n",
       " leggings      0.262191\n",
       " undershirt    0.240154\n",
       " blazer        0.223183\n",
       " skirt         0.213427\n",
       " jeans         0.211838\n",
       " pants         0.181322\n",
       " turtleneck    0.180997\n",
       " Name: sense145, dtype: float64, 'Top 4 Sense 1630', item\n",
       " pepperoni    0.423243\n",
       " bagel        0.375758\n",
       " tortilla     0.358551\n",
       " bread        0.354559\n",
       " cheese       0.343413\n",
       " croissant    0.300704\n",
       " sausage      0.295690\n",
       " quiche       0.247495\n",
       " toast        0.236572\n",
       " Name: sense1631, dtype: float64, 'Top 5 Sense 1910', item\n",
       " cornmeal     0.435816\n",
       " pasta        0.294711\n",
       " hummus       0.201902\n",
       " granola      0.199735\n",
       " oatmeal      0.184621\n",
       " bread        0.165810\n",
       " cereal       0.161673\n",
       " cornbread    0.159645\n",
       " rice         0.154483\n",
       " Name: sense1911, dtype: float64, 'Top 6 Sense 2178', item\n",
       " fern          0.222539\n",
       " clover        0.186026\n",
       " dandelion     0.150169\n",
       " poinsettia    0.146530\n",
       " cactus        0.125584\n",
       " pincushion    0.105802\n",
       " poppy         0.097345\n",
       " daisy         0.089445\n",
       " orchid        0.072495\n",
       " Name: sense2179, dtype: float64, 'Top 7 Sense 288', item\n",
       " cilantro    0.463003\n",
       " parsley     0.436178\n",
       " garlic      0.394036\n",
       " onion       0.338325\n",
       " clove       0.254602\n",
       " pesto       0.233927\n",
       " sauce       0.194905\n",
       " celery      0.194694\n",
       " butter      0.190050\n",
       " Name: sense289, dtype: float64, 'Top 8 Sense 743', item\n",
       " radish         0.638729\n",
       " sprouts        0.618966\n",
       " cabbage        0.605701\n",
       " broccoli       0.605002\n",
       " kale           0.556218\n",
       " zucchini       0.528219\n",
       " lettuce        0.527416\n",
       " cauliflower    0.521040\n",
       " celery         0.513640\n",
       " Name: sense744, dtype: float64, 'Top 9 Sense 1916', item\n",
       " hyena        0.389805\n",
       " squirrel     0.376564\n",
       " weasel       0.320919\n",
       " possum       0.301537\n",
       " otter        0.246704\n",
       " mongoose     0.244518\n",
       " cougar       0.243382\n",
       " porcupine    0.240225\n",
       " coyote       0.227595\n",
       " Name: sense1917, dtype: float64]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listOfWeights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
